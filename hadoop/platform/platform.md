#### 大数据平台构成
- 存储计算平台
- 数据开发平台
- 数据采集系统
- 数据仓库
- 调度系统
- 数据服务系统

这几部分是相互依托的存在。

#### 存储计算平台
存储计算平台是基于CDH发行版，采用Hadoop生态HDFS、HBase、Hive、Kudu、spark、flink、presto等组件自建的大数据基础平台。
#### 数据采集系统
数据采集系统主要完成异构数据源、多样化数据需求的一站式数据采集，其依托于数据开发平台的配置管理、调度系统的任务调度等最终将数据汇集到存储和计算平台用于完成后续的数据加工和数据生产。基于Kafka为数据总线，按照数据源划分为MySQL数据源和非MySQL数据源，MySQL数据源采用canal监听MySQL的二进制日志推送到Kafka，非MySQL数据源基于Kafka为数据总线，由业务方推送数据到数据总线。采用flink流计算框架开发实时数据采集模块将数据从数据总线中取出进行一定的清洗后分别存储到HDFS用于T+1的数据加工和生产，存储到Kudu用于实时数据需求。

#### 任务调度系统
基于airflow进行二次集成开发的任务调度平台。主要调度和管理HDFS到HIVE的数据清洗和加载任务、数据仓库层级间的数据加工任务，HIVE到MySQL的数据生产任务等。任务的调度执行执行参数在数据开发平台中进行管理配置

#### 数据服务系统
数据服务系统依托于任务调度系统中的数据生产任务生产的数据以及kudu提供的数据，以API形式对外提供数据服务接口调用，保证高可用性。对风控、资方和业务运营提供实时查询用户历史借款行为，用户APP点击事件行为查询服务，实时交易指标计算和展示等业务。

#### 数据仓库
数据仓库是一种逻辑模型，按照分层理论将数据主要物理存储在HIVE，根据在数据开发平台中配置的数据层级、策略、周期、表结构定义、SQL脚本，由自主开发的SparkETL框架自动完成数据加工任务的执行。

#### 数据开发平台
数据开发平台设计的目标是简化数据接入的复杂度，降低数据接入门槛，提高数据效率，将大数据工程师从繁琐的取数逻辑中解放出来。主要有配置管理、任务定义和提交、数据监控、数据字典和权限管理等模块组成。数据产品经理，数据分析师、ETL工程师、数据开发工程师根据自己的权限配置管理和提交数据任务，任务提交后Commander服务发消息给kafka，Worker服务监听到kafka消息后从MySQL中读取任务配置异步完成对应的任务执行后更新任务状态。

#### 平台运维和部署
数据存储计算平台部署在阿里云ECS节点上，通过CDH的CM管理和监控。
数据采集系统中的canal部署在运维部维护的k8s平台上。
数据开发平台部署在k8s上
监控采用grafna,prometheuse



ETL任务按照数据处理流程划分为：
数据采集任务
数据加工任务
数据生产任务
按照时效性需求分为，实时和T+1，
T+1数据进入HIVE数据仓库，主要给数据分析师、数据产品提供数据支持。
实时数据进入KUDU，通过presto查询引擎提供给风控、实时指标大屏等应用提供数据服务。


主要由：
- 配置和管理模块。
  - 数据源管理
  - 元数据管理
  - 层级管理
  - 策略管理
  - 维度管理
- 任务提交模块
  - 表结构定义
  - SQL脚本提交
- 数据监控模块
  - 数据质量监控
  - 数据任务监控
- 数据字典